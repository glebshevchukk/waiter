
Waiter lets you deploy machine learning models built on Pytorch/Tensorflow/ONNX in production and:

* Deploy models in data centers, on embedded hardware, or locally
* Serve your models through an API or locally to other Python programs
* Optimize your models for speed, energy usage, and memory
* Visualize key diagnostics in a dashboard
* Automatically push models to clients and collect statistics from deployment
*  Perform federated learning to protect customer privacy
* Perform A/B testing with different models to push new models and sunset old ones
* Load balance inference requests in production
* Sync models across computers.
* Centrally store models and keep them updated across your team
